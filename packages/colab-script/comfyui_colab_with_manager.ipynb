{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wqdygkd/tool/blob/main/packages/colab-script/comfyui_colab_with_manager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# #@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "USE_ONEDRIVE = False # @param {\"type\":\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "if OPTIONS['USE_ONEDRIVE']:\n",
        "    !echo \"初始化onedrive...\"\n",
        "    %cd /\n",
        "\n",
        "    !curl  https://rclone.org/install.sh | sudo bash\n",
        "    !rm rclone.conf\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    !mkdir /root/.config/rclone/\n",
        "    !cp rclone.conf /root/.config/rclone/rclone.conf\n",
        "    !sudo apt install fuse3 -y\n",
        "\n",
        "    !sudo mkdir /content/onedrive\n",
        "    !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive  &\n",
        "\n",
        "    !ls /content/onedrive -la\n",
        "\n",
        "\n",
        "    #!fusermount -qzu /content/drive\n",
        "    #!sudo umount -l /content/drive\n",
        "    #!rm -r /content/drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \".ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/nightly/windows_base_files/run_nvidia_gpu.bat\" ] && chmod 755 .ci/nightly/windows_base_files/run_nvidia_gpu.bat\n",
        "  ![ -f \".ci/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows/update.py\" ] && chmod 755 .ci/update_windows/update.py\n",
        "  ![ -f \".ci/update_windows/update_comfyui.bat\" ] && chmod 755 .ci/update_windows/update_comfyui.bat\n",
        "  ![ -f \".ci/update_windows/README_VERY_IMPORTANT.txt\" ] && chmod 755 .ci/update_windows/README_VERY_IMPORTANT.txt\n",
        "  ![ -f \".ci/update_windows/run_cpu.bat\" ] && chmod 755 .ci/update_windows/run_cpu.bat\n",
        "  ![ -f \".ci/update_windows/run_nvidia_gpu.bat\" ] && chmod 755 .ci/update_windows/run_nvidia_gpu.bat\n",
        "\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate\n",
        "!pip3 install einops transformers>=4.28.1 safetensors>=0.4.2 aiohttp pyyaml Pillow scipy tqdm psutil tokenizers>=0.13.3\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip3 install torchsde\n",
        "!pip3 install kornia>=0.7.1 spandrel soundfile sentencepiece\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \"ComfyUI-Manager/check.sh\" ] && chmod 755 ComfyUI-Manager/check.sh\n",
        "  ![ -f \"ComfyUI-Manager/scan.sh\" ] && chmod 755 ComfyUI-Manager/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/dev/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/dev/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/tutorial/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/tutorial/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\n",
        "\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://civitai.com/api/download/models/618692 -O ./models/uned/flux_dev.safetensors"
      ],
      "metadata": {
        "id": "TH6pRbSy7AtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors -P ./models/unet/"
      ],
      "metadata": {
        "id": "MRZkDVkO7IvK",
        "outputId": "e49aa715-4288-4381-bcc5-19744babe89a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-06 16:43:55--  https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.34, 13.35.202.40, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1743961436&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mzk2MTQzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=SiY44tR4pQ6-iHFVkJ52Wcjm85LPzN0SSSXk6lIK%7EwbuwyQoRNtzpKnNFps195nC7vqTH2PrnAuxWC5ZHVLmHi-wdcrer6f6Ek0far3pp7BDDOjW887uVoEceKbNH3T5aKUuNTGdkAy6BFQd5MD3Ryf167iVdQlro622Id71Nxilf9RmSeujQQ059NAII4kBR%7Ey%7EkScs8coC7FTJ7qzQTuQA5EjuC26%7ED1-pc3Za7WjUXoJkYewUnsWm-dvonct4hNaUd642cSyVdp4JCHJabGFqth1btxORvWNLRUWC2A5py9CeP41J2EgFaHtNjxt9jOqIWH8hVfSKiTj52hxmMA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-06 16:43:56--  https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1743961436&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mzk2MTQzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=SiY44tR4pQ6-iHFVkJ52Wcjm85LPzN0SSSXk6lIK%7EwbuwyQoRNtzpKnNFps195nC7vqTH2PrnAuxWC5ZHVLmHi-wdcrer6f6Ek0far3pp7BDDOjW887uVoEceKbNH3T5aKUuNTGdkAy6BFQd5MD3Ryf167iVdQlro622Id71Nxilf9RmSeujQQ059NAII4kBR%7Ey%7EkScs8coC7FTJ7qzQTuQA5EjuC26%7ED1-pc3Za7WjUXoJkYewUnsWm-dvonct4hNaUd642cSyVdp4JCHJabGFqth1btxORvWNLRUWC2A5py9CeP41J2EgFaHtNjxt9jOqIWH8hVfSKiTj52hxmMA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.33.45.57, 13.33.45.64, 13.33.45.80, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.33.45.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11901525888 (11G) [binary/octet-stream]\n",
            "Saving to: ‘./models/unet/flux1-dev-fp8.safetensors’\n",
            "\n",
            "flux1-dev-fp8.safet 100%[===================>]  11.08G  59.6MB/s    in 4m 3s   \n",
            "\n",
            "2025-04-06 16:48:00 (46.6 MB/s) - ‘./models/unet/flux1-dev-fp8.safetensors’ saved [11901525888/11901525888]\n",
            "\n",
            "--2025-04-06 16:48:01--  https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.121, 13.35.202.40, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1743961681&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mzk2MTY4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=nHKjvdMYf2Qqk8Pw%7EHe69BtstKi8bz4ytjuzAkl23sgefOw5aoHwDdqju1stEJBIK%7EtzVb-RmsH5KdRgglp4cV0uia4m06jkU6beuxGSxPD5nwDpfI2Ud%7ETydMveJPWvjG2rLJ1KESgjqmRNCP-N-FSnCfs-nOom63OoMrKKAYQh8flrwVn6BqH6PkLmhm2UAJ3n63nlJeFyreHUQb7gJwTE1nn0o-StWGX1o3dyIfzAoOk2IvXTYlyXs0sXOsUB2%7EuwcFUHI08cpAbv596fy5SgJz1Kc9AMXZO8HsBJEUFYwqeDEyunosF1zK4V03pOJMEnvn48a7bu2j9EDdv4AQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-06 16:48:01--  https://cdn-lfs-us-1.hf.co/repos/fa/7f/fa7f815f89d4b2bcb4ae950e05293cb2f1e1621038b996c0a9829dbdf2a8da85/1be961341be8f5307ef26c787199f80bf4e0de3c1c0b4617095aa6ee5550dfce?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27flux1-dev-fp8.safetensors%3B+filename%3D%22flux1-dev-fp8.safetensors%22%3B&Expires=1743961681&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Mzk2MTY4MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2ZhLzdmL2ZhN2Y4MTVmODlkNGIyYmNiNGFlOTUwZTA1MjkzY2IyZjFlMTYyMTAzOGI5OTZjMGE5ODI5ZGJkZjJhOGRhODUvMWJlOTYxMzQxYmU4ZjUzMDdlZjI2Yzc4NzE5OWY4MGJmNGUwZGUzYzFjMGI0NjE3MDk1YWE2ZWU1NTUwZGZjZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=nHKjvdMYf2Qqk8Pw%7EHe69BtstKi8bz4ytjuzAkl23sgefOw5aoHwDdqju1stEJBIK%7EtzVb-RmsH5KdRgglp4cV0uia4m06jkU6beuxGSxPD5nwDpfI2Ud%7ETydMveJPWvjG2rLJ1KESgjqmRNCP-N-FSnCfs-nOom63OoMrKKAYQh8flrwVn6BqH6PkLmhm2UAJ3n63nlJeFyreHUQb7gJwTE1nn0o-StWGX1o3dyIfzAoOk2IvXTYlyXs0sXOsUB2%7EuwcFUHI08cpAbv596fy5SgJz1Kc9AMXZO8HsBJEUFYwqeDEyunosF1zK4V03pOJMEnvn48a7bu2j9EDdv4AQ__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.35.202.113, 13.35.202.120, 13.35.202.18, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.35.202.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoints\n",
        "\n",
        "# flux1-dev-fp8\n",
        "#!wget -c https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/flux1-dev.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# flux1-dev-fp8\n",
        "!wget -c https://huggingface.co/Kijai/flux-fp8/resolve/main/flux1-dev-fp8.safetensors -P ./models/unet/\n",
        "#!wget -c https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# clip\n",
        "!wget -c https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors -P ./models/text_encoders/\n",
        "!wget -c https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn.safetensors -P ./models/text_encoders/\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/ae.safetensors -P ./models/vae/\n"
      ],
      "metadata": {
        "id": "um-bGwSvxJqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd"
      },
      "outputs": [],
      "source": [
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/ae.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "outputId": "24cdb4e5-10ca-4ce2-e922-4faab9633f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight'])                                         \n",
            "import network module: .networks.lora_flux\n",
            "                    ERROR    !!! Exception during processing !!! Cannot copy out of execution.py:396\n",
            "                             meta tensor; no data! Please use                                       \n",
            "                             torch.nn.Module.to_empty() instead of                                  \n",
            "                             torch.nn.Module.to() when moving module from meta to a                 \n",
            "                             different device.                                                      \n",
            "                    ERROR    Traceback (most recent call last):                     execution.py:397\n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 327, in execute                                                   \n",
            "                                 output_data, output_ui, has_subgraph =                             \n",
            "                             get_output_data(obj, input_data_all,                                   \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                                        ^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 202, in get_output_data                                           \n",
            "                                 return_values = _map_node_over_list(obj,                           \n",
            "                             input_data_all, obj.FUNCTION, allow_interrupt=True,                    \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^                                                                   \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 174, in _map_node_over_list                                       \n",
            "                                 process_inputs(input_dict, i)                                      \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 163, in process_inputs                                            \n",
            "                                 results.append(getattr(obj, func)(**inputs))                       \n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                        \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/nodes.py\", line 631, in init_training                       \n",
            "                                 training_loop = network_trainer.init_train(args)                   \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/train_network.py\", line 449, in init_train                  \n",
            "                                 vae.to(accelerator.device, dtype=vae_dtype)                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1343, in to                                       \n",
            "                                 return self._apply(convert)                                        \n",
            "                                        ^^^^^^^^^^^^^^^^^^^^                                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 930, in _apply                                    \n",
            "                                 param_applied = fn(param)                                          \n",
            "                                                 ^^^^^^^^^                                          \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1336, in convert                                  \n",
            "                                 raise NotImplementedError(                                         \n",
            "                             NotImplementedError: Cannot copy out of meta tensor;                   \n",
            "                             no data! Please use torch.nn.Module.to_empty() instead                 \n",
            "                             of torch.nn.Module.to() when moving module from meta                   \n",
            "                             to a different device.                                                 \n",
            "                                                                                                    \n",
            "                    INFO     Prompt executed in 3.82 seconds                             main.py:189\n",
            "2025-04-06 16:59:35 INFO     got prompt                                                server.py:627\n",
            "                    ERROR    Failed to validate prompt for output 130:              execution.py:832\n",
            "                    ERROR    * AddLabel 80:                                         execution.py:852\n",
            "                    ERROR      - Required input is missing: image                   execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 46:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 46:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 61:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 61:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 66:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 66:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "queue_counter: 0\n",
            "additional_args: \n",
            "2025-04-06 16:59:35 INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     t5xxl_max_token_length: 512             flux_train_network_comfy.py:111\n",
            "2025-04-06 16:59:36 INFO     Loading dataset config from [[datasets]]           train_network.py:342\n",
            "                             resolution = [ 512, 512,]                                              \n",
            "                             batch_size = 1                                                         \n",
            "                             enable_bucket = true                                                   \n",
            "                             bucket_no_upscale = false                                              \n",
            "                             min_bucket_reso = 256                                                  \n",
            "                             max_bucket_reso = 1024                                                 \n",
            "                             [[datasets.subsets]]                                                   \n",
            "                             image_dir = \"/content/drive/MyDrive/AI/小恩\"                           \n",
            "                             class_tokens = \"akihikoyoshida\"                                        \n",
            "                             num_repeats = 1                                                        \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                             [general]                                                              \n",
            "                             shuffle_caption = false                                                \n",
            "                             caption_extension = \".txt\"                                             \n",
            "                             keep_tokens_separator = \"|||\"                                          \n",
            "                             caption_dropout_rate = 0.0                                             \n",
            "                             color_aug = false                                                      \n",
            "                             flip_aug = false                                                       \n",
            "                                                                                                    \n",
            "                    INFO     prepare images.                                      train_util.py:1955\n",
            "                    INFO     get image size from name of cache files              train_util.py:1864\n",
            "100% 54/54 [00:00<00:00, 39791.36it/s]\n",
            "                    INFO     set image size from cache files: 0/54                train_util.py:1894\n",
            "                    INFO     found directory /content/drive/MyDrive/AI/小恩       train_util.py:1896\n",
            "                             contains 54 image files                                                \n",
            "read caption: 100% 54/54 [00:00<00:00, 2962.70it/s]\n",
            "2025-04-06 16:59:37 INFO     Found captions for 0 images.                         train_util.py:1926\n",
            "                    WARNING  No caption file found for 54 images. Training will   train_util.py:1933\n",
            "                             continue without captions for these images. If class                   \n",
            "                             token exists, it will be used. /                                       \n",
            "                             54枚の画像にキャプションファイルが見つかりませんでし                   \n",
            "                             た。これらの画像についてはキャプションなしで学習を続                   \n",
            "                             行します。class                                                        \n",
            "                             tokenが存在する場合はそれを使います。                                  \n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/02.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/03.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/04.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/05.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/06.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/07.jpg... and 49 more train_util.py:1938\n",
            "                    INFO     54 train images with repeating.                      train_util.py:1996\n",
            "                    INFO     0 reg images.                                        train_util.py:1999\n",
            "                    WARNING  no regularization images /                           train_util.py:2004\n",
            "                             正則化画像が見つかりませんでした                                       \n",
            "                    INFO     [Dataset 0]                                          config_util.py:567\n",
            "                               batch_size: 1                                                        \n",
            "                               resolution: (512, 512)                                               \n",
            "                               enable_bucket: True                                                  \n",
            "                               network_multiplier: 1.0                                              \n",
            "                               min_bucket_reso: 256                                                 \n",
            "                               max_bucket_reso: 1024                                                \n",
            "                               bucket_reso_steps: 64                                                \n",
            "                               bucket_no_upscale: False                                             \n",
            "                                                                                                    \n",
            "                               [Subset 0 of Dataset 0]                                              \n",
            "                                 image_dir: \"/content/drive/MyDrive/AI/小恩\"                        \n",
            "                                 image_count: 54                                                    \n",
            "                                 num_repeats: 1                                                     \n",
            "                                 shuffle_caption: False                                             \n",
            "                                 keep_tokens: 0                                                     \n",
            "                                 keep_tokens_separator: |||                                         \n",
            "                                 caption_separator: ,                                               \n",
            "                                 secondary_separator: None                                          \n",
            "                                 enable_wildcard: False                                             \n",
            "                                 caption_dropout_rate: 0.0                                          \n",
            "                                 caption_dropout_every_n_epochs: 0                                  \n",
            "                                 caption_tag_dropout_rate: 0.0                                      \n",
            "                                 caption_prefix: None                                               \n",
            "                                 caption_suffix: None                                               \n",
            "                                 color_aug: False                                                   \n",
            "                                 flip_aug: False                                                    \n",
            "                                 face_crop_aug_range: None                                          \n",
            "                                 random_crop: False                                                 \n",
            "                                 token_warmup_min: 1                                                \n",
            "                                 token_warmup_step: 0.0                                             \n",
            "                                 alpha_mask: False                                                  \n",
            "                                 custom_attributes: {}                                              \n",
            "                                 is_reg: False                                                      \n",
            "                                 class_tokens: akihikoyoshida                                       \n",
            "                                 caption_extension: .txt                                            \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                    INFO     [Dataset 0]                                          config_util.py:573\n",
            "                    INFO     loading image sizes.                                  train_util.py:918\n",
            "100% 54/54 [00:00<00:00, 364.09it/s]\n",
            "                    INFO     make buckets                                          train_util.py:924\n",
            "                    INFO     number of images (including repeats) /                train_util.py:970\n",
            "                             各bucketの画像枚数（繰り返し回数を含む）                               \n",
            "                    INFO     bucket 0: resolution (448, 576), count: 48            train_util.py:975\n",
            "                    INFO     bucket 1: resolution (576, 448), count: 6             train_util.py:975\n",
            "                    INFO     mean ar error (without repeats): 0.029987980283698975 train_util.py:980\n",
            "                    INFO     preparing accelerator                              train_network.py:407\n",
            "                    ERROR    !!! Exception during processing !!! AcceleratorState   execution.py:396\n",
            "                             has already been initialized and cannot be changed,                    \n",
            "                             restart your runtime completely and pass                               \n",
            "                             `mixed_precision='fp16'` to `Accelerator()`.                           \n",
            "                    ERROR    Traceback (most recent call last):                     execution.py:397\n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 327, in execute                                                   \n",
            "                                 output_data, output_ui, has_subgraph =                             \n",
            "                             get_output_data(obj, input_data_all,                                   \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                                        ^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 202, in get_output_data                                           \n",
            "                                 return_values = _map_node_over_list(obj,                           \n",
            "                             input_data_all, obj.FUNCTION, allow_interrupt=True,                    \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^                                                                   \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 174, in _map_node_over_list                                       \n",
            "                                 process_inputs(input_dict, i)                                      \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 163, in process_inputs                                            \n",
            "                                 results.append(getattr(obj, func)(**inputs))                       \n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                        \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/nodes.py\", line 631, in init_training                       \n",
            "                                 training_loop = network_trainer.init_train(args)                   \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/train_network.py\", line 408, in init_train                  \n",
            "                                 accelerator = train_util.prepare_accelerator(args)                 \n",
            "                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/library/train_util.py\", line 5181, in                       \n",
            "                             prepare_accelerator                                                    \n",
            "                                 accelerator = Accelerator(                                         \n",
            "                                               ^^^^^^^^^^^^                                         \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/ac                 \n",
            "                             celerator.py\", line 453, in __init__                                   \n",
            "                                 self.state = AcceleratorState(                                     \n",
            "                                              ^^^^^^^^^^^^^^^^^                                     \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/st                 \n",
            "                             ate.py\", line 898, in __init__                                         \n",
            "                                 self._check_initialized(mixed_precision, cpu)                      \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/st                 \n",
            "                             ate.py\", line 1012, in _check_initialized                              \n",
            "                                 raise                                                              \n",
            "                             ValueError(err.format(flag=f\"mixed_precision='{mixed_p                 \n",
            "                             recision}'\"))                                                          \n",
            "                             ValueError: AcceleratorState has already been                          \n",
            "                             initialized and cannot be changed, restart your                        \n",
            "                             runtime completely and pass `mixed_precision='fp16'`                   \n",
            "                             to `Accelerator()`.                                                    \n",
            "                                                                                                    \n",
            "                    INFO     Prompt executed in 1.43 seconds                             main.py:189\n",
            "2025-04-06 16:59:47 INFO     got prompt                                                server.py:627\n",
            "                    ERROR    Failed to validate prompt for output 130:              execution.py:832\n",
            "                    ERROR    * AddLabel 80:                                         execution.py:852\n",
            "                    ERROR      - Required input is missing: image                   execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 46:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 46:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 61:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 61:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 66:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 66:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "queue_counter: 0\n",
            "additional_args: \n",
            "2025-04-06 16:59:47 INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     t5xxl_max_token_length: 512             flux_train_network_comfy.py:111\n",
            "2025-04-06 16:59:48 INFO     Loading dataset config from [[datasets]]           train_network.py:342\n",
            "                             resolution = [ 512, 512,]                                              \n",
            "                             batch_size = 1                                                         \n",
            "                             enable_bucket = true                                                   \n",
            "                             bucket_no_upscale = false                                              \n",
            "                             min_bucket_reso = 256                                                  \n",
            "                             max_bucket_reso = 1024                                                 \n",
            "                             [[datasets.subsets]]                                                   \n",
            "                             image_dir = \"/content/drive/MyDrive/AI/小恩\"                           \n",
            "                             class_tokens = \"akihikoyoshida\"                                        \n",
            "                             num_repeats = 1                                                        \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                             [general]                                                              \n",
            "                             shuffle_caption = false                                                \n",
            "                             caption_extension = \".txt\"                                             \n",
            "                             keep_tokens_separator = \"|||\"                                          \n",
            "                             caption_dropout_rate = 0.0                                             \n",
            "                             color_aug = false                                                      \n",
            "                             flip_aug = false                                                       \n",
            "                                                                                                    \n",
            "                    INFO     prepare images.                                      train_util.py:1955\n",
            "                    INFO     get image size from name of cache files              train_util.py:1864\n",
            "100% 54/54 [00:00<00:00, 19148.83it/s]\n",
            "                    INFO     set image size from cache files: 0/54                train_util.py:1894\n",
            "                    INFO     found directory /content/drive/MyDrive/AI/小恩       train_util.py:1896\n",
            "                             contains 54 image files                                                \n",
            "read caption: 100% 54/54 [00:00<00:00, 1999.53it/s]\n",
            "2025-04-06 16:59:49 INFO     Found captions for 0 images.                         train_util.py:1926\n",
            "                    WARNING  No caption file found for 54 images. Training will   train_util.py:1933\n",
            "                             continue without captions for these images. If class                   \n",
            "                             token exists, it will be used. /                                       \n",
            "                             54枚の画像にキャプションファイルが見つかりませんでし                   \n",
            "                             た。これらの画像についてはキャプションなしで学習を続                   \n",
            "                             行します。class                                                        \n",
            "                             tokenが存在する場合はそれを使います。                                  \n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/02.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/03.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/04.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/05.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/06.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/07.jpg... and 49 more train_util.py:1938\n",
            "                    INFO     54 train images with repeating.                      train_util.py:1996\n",
            "                    INFO     0 reg images.                                        train_util.py:1999\n",
            "                    WARNING  no regularization images /                           train_util.py:2004\n",
            "                             正則化画像が見つかりませんでした                                       \n",
            "                    INFO     [Dataset 0]                                          config_util.py:567\n",
            "                               batch_size: 1                                                        \n",
            "                               resolution: (512, 512)                                               \n",
            "                               enable_bucket: True                                                  \n",
            "                               network_multiplier: 1.0                                              \n",
            "                               min_bucket_reso: 256                                                 \n",
            "                               max_bucket_reso: 1024                                                \n",
            "                               bucket_reso_steps: 64                                                \n",
            "                               bucket_no_upscale: False                                             \n",
            "                                                                                                    \n",
            "                               [Subset 0 of Dataset 0]                                              \n",
            "                                 image_dir: \"/content/drive/MyDrive/AI/小恩\"                        \n",
            "                                 image_count: 54                                                    \n",
            "                                 num_repeats: 1                                                     \n",
            "                                 shuffle_caption: False                                             \n",
            "                                 keep_tokens: 0                                                     \n",
            "                                 keep_tokens_separator: |||                                         \n",
            "                                 caption_separator: ,                                               \n",
            "                                 secondary_separator: None                                          \n",
            "                                 enable_wildcard: False                                             \n",
            "                                 caption_dropout_rate: 0.0                                          \n",
            "                                 caption_dropout_every_n_epochs: 0                                  \n",
            "                                 caption_tag_dropout_rate: 0.0                                      \n",
            "                                 caption_prefix: None                                               \n",
            "                                 caption_suffix: None                                               \n",
            "                                 color_aug: False                                                   \n",
            "                                 flip_aug: False                                                    \n",
            "                                 face_crop_aug_range: None                                          \n",
            "                                 random_crop: False                                                 \n",
            "                                 token_warmup_min: 1                                                \n",
            "                                 token_warmup_step: 0.0                                             \n",
            "                                 alpha_mask: False                                                  \n",
            "                                 custom_attributes: {}                                              \n",
            "                                 is_reg: False                                                      \n",
            "                                 class_tokens: akihikoyoshida                                       \n",
            "                                 caption_extension: .txt                                            \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                    INFO     [Dataset 0]                                          config_util.py:573\n",
            "                    INFO     loading image sizes.                                  train_util.py:918\n",
            "100% 54/54 [00:00<00:00, 461.10it/s]\n",
            "                    INFO     make buckets                                          train_util.py:924\n",
            "                    INFO     number of images (including repeats) /                train_util.py:970\n",
            "                             各bucketの画像枚数（繰り返し回数を含む）                               \n",
            "                    INFO     bucket 0: resolution (448, 576), count: 48            train_util.py:975\n",
            "                    INFO     bucket 1: resolution (576, 448), count: 6             train_util.py:975\n",
            "                    INFO     mean ar error (without repeats): 0.029987980283698975 train_util.py:980\n",
            "                    INFO     preparing accelerator                              train_network.py:407\n",
            "accelerator device: cuda\n",
            "                    INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     Building Flux model dev from BFL checkpoint            flux_utils.py:97\n",
            "                    INFO     Loading state dict from                               flux_utils.py:114\n",
            "                             /content/drive/MyDrive/ComfyUI/models/unet/flux1-dev-                  \n",
            "                             fp8.safetensors                                                        \n",
            "                    INFO     Loaded Flux: <All keys matched successfully>          flux_utils.py:132\n",
            "                    INFO     Loaded torch.float8_e4m3fn FLUX model    flux_train_network_comfy.py:69\n",
            "                    INFO     Building CLIP-L                                       flux_utils.py:158\n",
            "                    INFO     Loading state dict from                               flux_utils.py:254\n",
            "                             /content/drive/MyDrive/ComfyUI/models/text_encoders/c                  \n",
            "                             lip_l.safetensors                                                      \n",
            "                    INFO     Loaded CLIP-L: <All keys matched successfully>        flux_utils.py:257\n",
            "2025-04-06 16:59:50 INFO     Loading state dict from                               flux_utils.py:309\n",
            "                             /content/drive/MyDrive/ComfyUI/models/text_encoders/t                  \n",
            "                             5xxl_fp8_e4m3fn.safetensors                                            \n",
            "                    INFO     Loaded T5xxl: <All keys matched successfully>         flux_utils.py:312\n",
            "                    INFO     Loaded fp8 T5XXL model                   flux_train_network_comfy.py:94\n",
            "                    INFO     Building AutoEncoder                                  flux_utils.py:139\n",
            "                    INFO     Loading state dict from                               flux_utils.py:144\n",
            "                             /content/drive/MyDrive/ComfyUI/models/vae/ae.safetens                  \n",
            "                             ors                                                                    \n",
            "                    INFO     Loaded AE:                                            flux_utils.py:147\n",
            "                             _IncompatibleKeys(missing_keys=['encoder.conv_in.weig                  \n",
            "                             ht', 'encoder.conv_in.bias',                                           \n",
            "                             'encoder.down.0.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.0.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.0.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.0.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.0.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.0.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.0.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.0.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.0.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.0.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.0.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.0.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.0.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.0.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.0.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.0.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.0.downsample.conv.weight',                               \n",
            "                             'encoder.down.0.downsample.conv.bias',                                 \n",
            "                             'encoder.down.1.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.1.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.1.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.1.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.1.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.1.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.1.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.1.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.1.block.0.nin_shortcut.weight',                          \n",
            "                             'encoder.down.1.block.0.nin_shortcut.bias',                            \n",
            "                             'encoder.down.1.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.1.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.1.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.1.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.1.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.1.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.1.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.1.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.1.downsample.conv.weight',                               \n",
            "                             'encoder.down.1.downsample.conv.bias',                                 \n",
            "                             'encoder.down.2.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.2.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.2.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.2.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.2.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.2.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.2.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.2.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.2.block.0.nin_shortcut.weight',                          \n",
            "                             'encoder.down.2.block.0.nin_shortcut.bias',                            \n",
            "                             'encoder.down.2.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.2.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.2.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.2.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.2.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.2.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.2.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.2.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.2.downsample.conv.weight',                               \n",
            "                             'encoder.down.2.downsample.conv.bias',                                 \n",
            "                             'encoder.down.3.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.3.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.3.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.3.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.3.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.3.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.3.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.3.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.3.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.3.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.3.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.3.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.3.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.3.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.3.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.3.block.1.conv2.bias',                                   \n",
            "                             'encoder.mid.block_1.norm1.weight',                                    \n",
            "                             'encoder.mid.block_1.norm1.bias',                                      \n",
            "                             'encoder.mid.block_1.conv1.weight',                                    \n",
            "                             'encoder.mid.block_1.conv1.bias',                                      \n",
            "                             'encoder.mid.block_1.norm2.weight',                                    \n",
            "                             'encoder.mid.block_1.norm2.bias',                                      \n",
            "                             'encoder.mid.block_1.conv2.weight',                                    \n",
            "                             'encoder.mid.block_1.conv2.bias',                                      \n",
            "                             'encoder.mid.attn_1.norm.weight',                                      \n",
            "                             'encoder.mid.attn_1.norm.bias',                                        \n",
            "                             'encoder.mid.attn_1.q.weight',                                         \n",
            "                             'encoder.mid.attn_1.q.bias',                                           \n",
            "                             'encoder.mid.attn_1.k.weight',                                         \n",
            "                             'encoder.mid.attn_1.k.bias',                                           \n",
            "                             'encoder.mid.attn_1.v.weight',                                         \n",
            "                             'encoder.mid.attn_1.v.bias',                                           \n",
            "                             'encoder.mid.attn_1.proj_out.weight',                                  \n",
            "                             'encoder.mid.attn_1.proj_out.bias',                                    \n",
            "                             'encoder.mid.block_2.norm1.weight',                                    \n",
            "                             'encoder.mid.block_2.norm1.bias',                                      \n",
            "                             'encoder.mid.block_2.conv1.weight',                                    \n",
            "                             'encoder.mid.block_2.conv1.bias',                                      \n",
            "                             'encoder.mid.block_2.norm2.weight',                                    \n",
            "                             'encoder.mid.block_2.norm2.bias',                                      \n",
            "                             'encoder.mid.block_2.conv2.weight',                                    \n",
            "                             'encoder.mid.block_2.conv2.bias',                                      \n",
            "                             'encoder.norm_out.weight', 'encoder.norm_out.bias',                    \n",
            "                             'encoder.conv_out.weight', 'encoder.conv_out.bias',                    \n",
            "                             'decoder.conv_in.weight', 'decoder.conv_in.bias',                      \n",
            "                             'decoder.mid.block_1.norm1.weight',                                    \n",
            "                             'decoder.mid.block_1.norm1.bias',                                      \n",
            "                             'decoder.mid.block_1.conv1.weight',                                    \n",
            "                             'decoder.mid.block_1.conv1.bias',                                      \n",
            "                             'decoder.mid.block_1.norm2.weight',                                    \n",
            "                             'decoder.mid.block_1.norm2.bias',                                      \n",
            "                             'decoder.mid.block_1.conv2.weight',                                    \n",
            "                             'decoder.mid.block_1.conv2.bias',                                      \n",
            "                             'decoder.mid.attn_1.norm.weight',                                      \n",
            "                             'decoder.mid.attn_1.norm.bias',                                        \n",
            "                             'decoder.mid.attn_1.q.weight',                                         \n",
            "                             'decoder.mid.attn_1.q.bias',                                           \n",
            "                             'decoder.mid.attn_1.k.weight',                                         \n",
            "                             'decoder.mid.attn_1.k.bias',                                           \n",
            "                             'decoder.mid.attn_1.v.weight',                                         \n",
            "                             'decoder.mid.attn_1.v.bias',                                           \n",
            "                             'decoder.mid.attn_1.proj_out.weight',                                  \n",
            "                             'decoder.mid.attn_1.proj_out.bias',                                    \n",
            "                             'decoder.mid.block_2.norm1.weight',                                    \n",
            "                             'decoder.mid.block_2.norm1.bias',                                      \n",
            "                             'decoder.mid.block_2.conv1.weight',                                    \n",
            "                             'decoder.mid.block_2.conv1.bias',                                      \n",
            "                             'decoder.mid.block_2.norm2.weight',                                    \n",
            "                             'decoder.mid.block_2.norm2.bias',                                      \n",
            "                             'decoder.mid.block_2.conv2.weight',                                    \n",
            "                             'decoder.mid.block_2.conv2.bias',                                      \n",
            "                             'decoder.up.0.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.0.block.0.nin_shortcut.weight',                            \n",
            "                             'decoder.up.0.block.0.nin_shortcut.bias',                              \n",
            "                             'decoder.up.0.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.0.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.0.nin_shortcut.weight',                            \n",
            "                             'decoder.up.1.block.0.nin_shortcut.bias',                              \n",
            "                             'decoder.up.1.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.1.upsample.conv.weight',                                   \n",
            "                             'decoder.up.1.upsample.conv.bias',                                     \n",
            "                             'decoder.up.2.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.2.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.2.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.2.upsample.conv.weight',                                   \n",
            "                             'decoder.up.2.upsample.conv.bias',                                     \n",
            "                             'decoder.up.3.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.3.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.3.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.3.upsample.conv.weight',                                   \n",
            "                             'decoder.up.3.upsample.conv.bias',                                     \n",
            "                             'decoder.norm_out.weight', 'decoder.norm_out.bias',                    \n",
            "                             'decoder.conv_out.weight', 'decoder.conv_out.bias'],                   \n",
            "                             unexpected_keys=['lora_te_text_model_encoder_layers_0                  \n",
            "                             _mlp_fc1.alpha',                                                       \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.alpha',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.lora_down.weight',                                                 \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.lora_up.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.alpha',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.lora_down.weight',                                                 \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.lora_up.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.alpha',                      \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.lora_down.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.lora_up.wei                  \n",
            "                             ght',                                                                  \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.alpha',                     \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.lora_down.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.lora_up.we                  \n",
            "                             ight',                                                                 \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.alpha',                                               \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.lora_down.weight',                                    \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.lora_up.weight',                                      \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.alpha',                                               \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.lora_down.weight',                                    \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.lora_up.weight',                                      \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.alpha',                                                \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.lora_down.weight',                                     \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.lora_up.weight',                                       \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.alpha',                                                     \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.lora_down.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.lora_up.weight',                                            \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight'])                                         \n",
            "import network module: .networks.lora_flux\n",
            "                    ERROR    !!! Exception during processing !!! Cannot copy out of execution.py:396\n",
            "                             meta tensor; no data! Please use                                       \n",
            "                             torch.nn.Module.to_empty() instead of                                  \n",
            "                             torch.nn.Module.to() when moving module from meta to a                 \n",
            "                             different device.                                                      \n",
            "                    ERROR    Traceback (most recent call last):                     execution.py:397\n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 327, in execute                                                   \n",
            "                                 output_data, output_ui, has_subgraph =                             \n",
            "                             get_output_data(obj, input_data_all,                                   \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                                        ^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 202, in get_output_data                                           \n",
            "                                 return_values = _map_node_over_list(obj,                           \n",
            "                             input_data_all, obj.FUNCTION, allow_interrupt=True,                    \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^                                                                   \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 174, in _map_node_over_list                                       \n",
            "                                 process_inputs(input_dict, i)                                      \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 163, in process_inputs                                            \n",
            "                                 results.append(getattr(obj, func)(**inputs))                       \n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                        \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/nodes.py\", line 631, in init_training                       \n",
            "                                 training_loop = network_trainer.init_train(args)                   \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/train_network.py\", line 449, in init_train                  \n",
            "                                 vae.to(accelerator.device, dtype=vae_dtype)                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1343, in to                                       \n",
            "                                 return self._apply(convert)                                        \n",
            "                                        ^^^^^^^^^^^^^^^^^^^^                                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 930, in _apply                                    \n",
            "                                 param_applied = fn(param)                                          \n",
            "                                                 ^^^^^^^^^                                          \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1336, in convert                                  \n",
            "                                 raise NotImplementedError(                                         \n",
            "                             NotImplementedError: Cannot copy out of meta tensor;                   \n",
            "                             no data! Please use torch.nn.Module.to_empty() instead                 \n",
            "                             of torch.nn.Module.to() when moving module from meta                   \n",
            "                             to a different device.                                                 \n",
            "                                                                                                    \n",
            "                    INFO     Prompt executed in 2.95 seconds                             main.py:189\n",
            "2025-04-06 17:02:08 INFO     got prompt                                                server.py:627\n",
            "                    ERROR    Failed to validate prompt for output 130:              execution.py:832\n",
            "                    ERROR    * AddLabel 80:                                         execution.py:852\n",
            "                    ERROR      - Required input is missing: image                   execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 46:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 46:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 61:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 61:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 66:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 66:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "queue_counter: 0\n",
            "additional_args: \n",
            "2025-04-06 17:02:08 INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     t5xxl_max_token_length: 512             flux_train_network_comfy.py:111\n",
            "2025-04-06 17:02:09 INFO     Loading dataset config from [[datasets]]           train_network.py:342\n",
            "                             resolution = [ 512, 512,]                                              \n",
            "                             batch_size = 1                                                         \n",
            "                             enable_bucket = true                                                   \n",
            "                             bucket_no_upscale = false                                              \n",
            "                             min_bucket_reso = 256                                                  \n",
            "                             max_bucket_reso = 1024                                                 \n",
            "                             [[datasets.subsets]]                                                   \n",
            "                             image_dir = \"/content/drive/MyDrive/AI/小恩\"                           \n",
            "                             class_tokens = \"akihikoyoshida\"                                        \n",
            "                             num_repeats = 1                                                        \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                             [general]                                                              \n",
            "                             shuffle_caption = false                                                \n",
            "                             caption_extension = \".txt\"                                             \n",
            "                             keep_tokens_separator = \"|||\"                                          \n",
            "                             caption_dropout_rate = 0.0                                             \n",
            "                             color_aug = false                                                      \n",
            "                             flip_aug = false                                                       \n",
            "                                                                                                    \n",
            "                    INFO     prepare images.                                      train_util.py:1955\n",
            "                    INFO     get image size from name of cache files              train_util.py:1864\n",
            "100% 54/54 [00:00<00:00, 34722.12it/s]\n",
            "                    INFO     set image size from cache files: 0/54                train_util.py:1894\n",
            "                    INFO     found directory /content/drive/MyDrive/AI/小恩       train_util.py:1896\n",
            "                             contains 54 image files                                                \n",
            "read caption: 100% 54/54 [00:00<00:00, 3410.26it/s]\n",
            "                    INFO     Found captions for 0 images.                         train_util.py:1926\n",
            "                    WARNING  No caption file found for 54 images. Training will   train_util.py:1933\n",
            "                             continue without captions for these images. If class                   \n",
            "                             token exists, it will be used. /                                       \n",
            "                             54枚の画像にキャプションファイルが見つかりませんでし                   \n",
            "                             た。これらの画像についてはキャプションなしで学習を続                   \n",
            "                             行します。class                                                        \n",
            "                             tokenが存在する場合はそれを使います。                                  \n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/02.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/03.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/04.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/05.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/06.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/07.jpg... and 49 more train_util.py:1938\n",
            "                    INFO     54 train images with repeating.                      train_util.py:1996\n",
            "                    INFO     0 reg images.                                        train_util.py:1999\n",
            "                    WARNING  no regularization images /                           train_util.py:2004\n",
            "                             正則化画像が見つかりませんでした                                       \n",
            "                    INFO     [Dataset 0]                                          config_util.py:567\n",
            "                               batch_size: 1                                                        \n",
            "                               resolution: (512, 512)                                               \n",
            "                               enable_bucket: True                                                  \n",
            "                               network_multiplier: 1.0                                              \n",
            "                               min_bucket_reso: 256                                                 \n",
            "                               max_bucket_reso: 1024                                                \n",
            "                               bucket_reso_steps: 64                                                \n",
            "                               bucket_no_upscale: False                                             \n",
            "                                                                                                    \n",
            "                               [Subset 0 of Dataset 0]                                              \n",
            "                                 image_dir: \"/content/drive/MyDrive/AI/小恩\"                        \n",
            "                                 image_count: 54                                                    \n",
            "                                 num_repeats: 1                                                     \n",
            "                                 shuffle_caption: False                                             \n",
            "                                 keep_tokens: 0                                                     \n",
            "                                 keep_tokens_separator: |||                                         \n",
            "                                 caption_separator: ,                                               \n",
            "                                 secondary_separator: None                                          \n",
            "                                 enable_wildcard: False                                             \n",
            "                                 caption_dropout_rate: 0.0                                          \n",
            "                                 caption_dropout_every_n_epochs: 0                                  \n",
            "                                 caption_tag_dropout_rate: 0.0                                      \n",
            "                                 caption_prefix: None                                               \n",
            "                                 caption_suffix: None                                               \n",
            "                                 color_aug: False                                                   \n",
            "                                 flip_aug: False                                                    \n",
            "                                 face_crop_aug_range: None                                          \n",
            "                                 random_crop: False                                                 \n",
            "                                 token_warmup_min: 1                                                \n",
            "                                 token_warmup_step: 0.0                                             \n",
            "                                 alpha_mask: False                                                  \n",
            "                                 custom_attributes: {}                                              \n",
            "                                 is_reg: False                                                      \n",
            "                                 class_tokens: akihikoyoshida                                       \n",
            "                                 caption_extension: .txt                                            \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                    INFO     [Dataset 0]                                          config_util.py:573\n",
            "                    INFO     loading image sizes.                                  train_util.py:918\n",
            "100% 54/54 [00:00<00:00, 371.76it/s]\n",
            "                    INFO     make buckets                                          train_util.py:924\n",
            "                    INFO     number of images (including repeats) /                train_util.py:970\n",
            "                             各bucketの画像枚数（繰り返し回数を含む）                               \n",
            "                    INFO     bucket 0: resolution (448, 576), count: 48            train_util.py:975\n",
            "                    INFO     bucket 1: resolution (576, 448), count: 6             train_util.py:975\n",
            "                    INFO     mean ar error (without repeats): 0.029987980283698975 train_util.py:980\n",
            "                    INFO     preparing accelerator                              train_network.py:407\n",
            "                    ERROR    !!! Exception during processing !!! AcceleratorState   execution.py:396\n",
            "                             has already been initialized and cannot be changed,                    \n",
            "                             restart your runtime completely and pass                               \n",
            "                             `mixed_precision='fp16'` to `Accelerator()`.                           \n",
            "                    ERROR    Traceback (most recent call last):                     execution.py:397\n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 327, in execute                                                   \n",
            "                                 output_data, output_ui, has_subgraph =                             \n",
            "                             get_output_data(obj, input_data_all,                                   \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                                        ^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 202, in get_output_data                                           \n",
            "                                 return_values = _map_node_over_list(obj,                           \n",
            "                             input_data_all, obj.FUNCTION, allow_interrupt=True,                    \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^                                                                   \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 174, in _map_node_over_list                                       \n",
            "                                 process_inputs(input_dict, i)                                      \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 163, in process_inputs                                            \n",
            "                                 results.append(getattr(obj, func)(**inputs))                       \n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                        \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/nodes.py\", line 631, in init_training                       \n",
            "                                 training_loop = network_trainer.init_train(args)                   \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/train_network.py\", line 408, in init_train                  \n",
            "                                 accelerator = train_util.prepare_accelerator(args)                 \n",
            "                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/library/train_util.py\", line 5181, in                       \n",
            "                             prepare_accelerator                                                    \n",
            "                                 accelerator = Accelerator(                                         \n",
            "                                               ^^^^^^^^^^^^                                         \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/ac                 \n",
            "                             celerator.py\", line 453, in __init__                                   \n",
            "                                 self.state = AcceleratorState(                                     \n",
            "                                              ^^^^^^^^^^^^^^^^^                                     \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/st                 \n",
            "                             ate.py\", line 898, in __init__                                         \n",
            "                                 self._check_initialized(mixed_precision, cpu)                      \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/accelerate/st                 \n",
            "                             ate.py\", line 1012, in _check_initialized                              \n",
            "                                 raise                                                              \n",
            "                             ValueError(err.format(flag=f\"mixed_precision='{mixed_p                 \n",
            "                             recision}'\"))                                                          \n",
            "                             ValueError: AcceleratorState has already been                          \n",
            "                             initialized and cannot be changed, restart your                        \n",
            "                             runtime completely and pass `mixed_precision='fp16'`                   \n",
            "                             to `Accelerator()`.                                                    \n",
            "                                                                                                    \n",
            "                    INFO     Prompt executed in 1.31 seconds                             main.py:189\n",
            "2025-04-06 17:02:22 INFO     got prompt                                                server.py:627\n",
            "2025-04-06 17:02:23 ERROR    Failed to validate prompt for output 130:              execution.py:832\n",
            "                    ERROR    * AddLabel 80:                                         execution.py:852\n",
            "                    ERROR      - Required input is missing: image                   execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 46:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 46:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 61:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 61:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "                    ERROR    Failed to validate prompt for output 66:               execution.py:832\n",
            "                    ERROR    * (prompt):                                            execution.py:834\n",
            "                    ERROR      - Required input is missing: images                  execution.py:836\n",
            "                    ERROR    * PreviewImage 66:                                     execution.py:852\n",
            "                    ERROR      - Required input is missing: images                  execution.py:854\n",
            "                    ERROR    Output will be ignored                                 execution.py:856\n",
            "queue_counter: 0\n",
            "additional_args: \n",
            "2025-04-06 17:02:23 INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     t5xxl_max_token_length: 512             flux_train_network_comfy.py:111\n",
            "2025-04-06 17:02:24 INFO     Loading dataset config from [[datasets]]           train_network.py:342\n",
            "                             resolution = [ 512, 512,]                                              \n",
            "                             batch_size = 1                                                         \n",
            "                             enable_bucket = true                                                   \n",
            "                             bucket_no_upscale = false                                              \n",
            "                             min_bucket_reso = 256                                                  \n",
            "                             max_bucket_reso = 1024                                                 \n",
            "                             [[datasets.subsets]]                                                   \n",
            "                             image_dir = \"/content/drive/MyDrive/AI/小恩\"                           \n",
            "                             class_tokens = \"akihikoyoshida\"                                        \n",
            "                             num_repeats = 1                                                        \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                             [general]                                                              \n",
            "                             shuffle_caption = false                                                \n",
            "                             caption_extension = \".txt\"                                             \n",
            "                             keep_tokens_separator = \"|||\"                                          \n",
            "                             caption_dropout_rate = 0.0                                             \n",
            "                             color_aug = false                                                      \n",
            "                             flip_aug = false                                                       \n",
            "                                                                                                    \n",
            "                    INFO     prepare images.                                      train_util.py:1955\n",
            "                    INFO     get image size from name of cache files              train_util.py:1864\n",
            "100% 54/54 [00:00<00:00, 43149.63it/s]\n",
            "                    INFO     set image size from cache files: 0/54                train_util.py:1894\n",
            "                    INFO     found directory /content/drive/MyDrive/AI/小恩       train_util.py:1896\n",
            "                             contains 54 image files                                                \n",
            "read caption: 100% 54/54 [00:00<00:00, 1925.07it/s]\n",
            "                    INFO     Found captions for 0 images.                         train_util.py:1926\n",
            "                    WARNING  No caption file found for 54 images. Training will   train_util.py:1933\n",
            "                             continue without captions for these images. If class                   \n",
            "                             token exists, it will be used. /                                       \n",
            "                             54枚の画像にキャプションファイルが見つかりませんでし                   \n",
            "                             た。これらの画像についてはキャプションなしで学習を続                   \n",
            "                             行します。class                                                        \n",
            "                             tokenが存在する場合はそれを使います。                                  \n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/02.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/03.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/04.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/05.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/06.jpg                train_util.py:1940\n",
            "                    WARNING  /content/drive/MyDrive/AI/小恩/07.jpg... and 49 more train_util.py:1938\n",
            "                    INFO     54 train images with repeating.                      train_util.py:1996\n",
            "                    INFO     0 reg images.                                        train_util.py:1999\n",
            "                    WARNING  no regularization images /                           train_util.py:2004\n",
            "                             正則化画像が見つかりませんでした                                       \n",
            "                    INFO     [Dataset 0]                                          config_util.py:567\n",
            "                               batch_size: 1                                                        \n",
            "                               resolution: (512, 512)                                               \n",
            "                               enable_bucket: True                                                  \n",
            "                               network_multiplier: 1.0                                              \n",
            "                               min_bucket_reso: 256                                                 \n",
            "                               max_bucket_reso: 1024                                                \n",
            "                               bucket_reso_steps: 64                                                \n",
            "                               bucket_no_upscale: False                                             \n",
            "                                                                                                    \n",
            "                               [Subset 0 of Dataset 0]                                              \n",
            "                                 image_dir: \"/content/drive/MyDrive/AI/小恩\"                        \n",
            "                                 image_count: 54                                                    \n",
            "                                 num_repeats: 1                                                     \n",
            "                                 shuffle_caption: False                                             \n",
            "                                 keep_tokens: 0                                                     \n",
            "                                 keep_tokens_separator: |||                                         \n",
            "                                 caption_separator: ,                                               \n",
            "                                 secondary_separator: None                                          \n",
            "                                 enable_wildcard: False                                             \n",
            "                                 caption_dropout_rate: 0.0                                          \n",
            "                                 caption_dropout_every_n_epochs: 0                                  \n",
            "                                 caption_tag_dropout_rate: 0.0                                      \n",
            "                                 caption_prefix: None                                               \n",
            "                                 caption_suffix: None                                               \n",
            "                                 color_aug: False                                                   \n",
            "                                 flip_aug: False                                                    \n",
            "                                 face_crop_aug_range: None                                          \n",
            "                                 random_crop: False                                                 \n",
            "                                 token_warmup_min: 1                                                \n",
            "                                 token_warmup_step: 0.0                                             \n",
            "                                 alpha_mask: False                                                  \n",
            "                                 custom_attributes: {}                                              \n",
            "                                 is_reg: False                                                      \n",
            "                                 class_tokens: akihikoyoshida                                       \n",
            "                                 caption_extension: .txt                                            \n",
            "                                                                                                    \n",
            "                                                                                                    \n",
            "                    INFO     [Dataset 0]                                          config_util.py:573\n",
            "                    INFO     loading image sizes.                                  train_util.py:918\n",
            "100% 54/54 [00:00<00:00, 476.16it/s]\n",
            "2025-04-06 17:02:25 INFO     make buckets                                          train_util.py:924\n",
            "                    INFO     number of images (including repeats) /                train_util.py:970\n",
            "                             各bucketの画像枚数（繰り返し回数を含む）                               \n",
            "                    INFO     bucket 0: resolution (448, 576), count: 48            train_util.py:975\n",
            "                    INFO     bucket 1: resolution (576, 448), count: 6             train_util.py:975\n",
            "                    INFO     mean ar error (without repeats): 0.029987980283698975 train_util.py:980\n",
            "                    INFO     preparing accelerator                              train_network.py:407\n",
            "accelerator device: cuda\n",
            "                    INFO     Checking the state dict: Diffusers or BFL, dev or      flux_utils.py:40\n",
            "                             schnell                                                                \n",
            "                    INFO     Building Flux model dev from BFL checkpoint            flux_utils.py:97\n",
            "                    INFO     Loading state dict from                               flux_utils.py:114\n",
            "                             /content/drive/MyDrive/ComfyUI/models/unet/flux1-dev-                  \n",
            "                             fp8.safetensors                                                        \n",
            "                    INFO     Loaded Flux: <All keys matched successfully>          flux_utils.py:132\n",
            "                    INFO     Loaded torch.float8_e4m3fn FLUX model    flux_train_network_comfy.py:69\n",
            "                    INFO     Building CLIP-L                                       flux_utils.py:158\n",
            "                    INFO     Loading state dict from                               flux_utils.py:254\n",
            "                             /content/drive/MyDrive/ComfyUI/models/text_encoders/c                  \n",
            "                             lip_l.safetensors                                                      \n",
            "                    INFO     Loaded CLIP-L: <All keys matched successfully>        flux_utils.py:257\n",
            "                    INFO     Loading state dict from                               flux_utils.py:309\n",
            "                             /content/drive/MyDrive/ComfyUI/models/text_encoders/t                  \n",
            "                             5xxl_fp8_e4m3fn.safetensors                                            \n",
            "2025-04-06 17:02:26 INFO     Loaded T5xxl: <All keys matched successfully>         flux_utils.py:312\n",
            "                    INFO     Loaded fp8 T5XXL model                   flux_train_network_comfy.py:94\n",
            "                    INFO     Building AutoEncoder                                  flux_utils.py:139\n",
            "                    INFO     Loading state dict from                               flux_utils.py:144\n",
            "                             /content/drive/MyDrive/ComfyUI/models/vae/ae.safetens                  \n",
            "                             ors                                                                    \n",
            "                    INFO     Loaded AE:                                            flux_utils.py:147\n",
            "                             _IncompatibleKeys(missing_keys=['encoder.conv_in.weig                  \n",
            "                             ht', 'encoder.conv_in.bias',                                           \n",
            "                             'encoder.down.0.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.0.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.0.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.0.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.0.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.0.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.0.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.0.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.0.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.0.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.0.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.0.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.0.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.0.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.0.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.0.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.0.downsample.conv.weight',                               \n",
            "                             'encoder.down.0.downsample.conv.bias',                                 \n",
            "                             'encoder.down.1.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.1.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.1.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.1.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.1.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.1.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.1.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.1.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.1.block.0.nin_shortcut.weight',                          \n",
            "                             'encoder.down.1.block.0.nin_shortcut.bias',                            \n",
            "                             'encoder.down.1.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.1.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.1.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.1.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.1.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.1.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.1.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.1.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.1.downsample.conv.weight',                               \n",
            "                             'encoder.down.1.downsample.conv.bias',                                 \n",
            "                             'encoder.down.2.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.2.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.2.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.2.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.2.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.2.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.2.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.2.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.2.block.0.nin_shortcut.weight',                          \n",
            "                             'encoder.down.2.block.0.nin_shortcut.bias',                            \n",
            "                             'encoder.down.2.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.2.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.2.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.2.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.2.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.2.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.2.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.2.block.1.conv2.bias',                                   \n",
            "                             'encoder.down.2.downsample.conv.weight',                               \n",
            "                             'encoder.down.2.downsample.conv.bias',                                 \n",
            "                             'encoder.down.3.block.0.norm1.weight',                                 \n",
            "                             'encoder.down.3.block.0.norm1.bias',                                   \n",
            "                             'encoder.down.3.block.0.conv1.weight',                                 \n",
            "                             'encoder.down.3.block.0.conv1.bias',                                   \n",
            "                             'encoder.down.3.block.0.norm2.weight',                                 \n",
            "                             'encoder.down.3.block.0.norm2.bias',                                   \n",
            "                             'encoder.down.3.block.0.conv2.weight',                                 \n",
            "                             'encoder.down.3.block.0.conv2.bias',                                   \n",
            "                             'encoder.down.3.block.1.norm1.weight',                                 \n",
            "                             'encoder.down.3.block.1.norm1.bias',                                   \n",
            "                             'encoder.down.3.block.1.conv1.weight',                                 \n",
            "                             'encoder.down.3.block.1.conv1.bias',                                   \n",
            "                             'encoder.down.3.block.1.norm2.weight',                                 \n",
            "                             'encoder.down.3.block.1.norm2.bias',                                   \n",
            "                             'encoder.down.3.block.1.conv2.weight',                                 \n",
            "                             'encoder.down.3.block.1.conv2.bias',                                   \n",
            "                             'encoder.mid.block_1.norm1.weight',                                    \n",
            "                             'encoder.mid.block_1.norm1.bias',                                      \n",
            "                             'encoder.mid.block_1.conv1.weight',                                    \n",
            "                             'encoder.mid.block_1.conv1.bias',                                      \n",
            "                             'encoder.mid.block_1.norm2.weight',                                    \n",
            "                             'encoder.mid.block_1.norm2.bias',                                      \n",
            "                             'encoder.mid.block_1.conv2.weight',                                    \n",
            "                             'encoder.mid.block_1.conv2.bias',                                      \n",
            "                             'encoder.mid.attn_1.norm.weight',                                      \n",
            "                             'encoder.mid.attn_1.norm.bias',                                        \n",
            "                             'encoder.mid.attn_1.q.weight',                                         \n",
            "                             'encoder.mid.attn_1.q.bias',                                           \n",
            "                             'encoder.mid.attn_1.k.weight',                                         \n",
            "                             'encoder.mid.attn_1.k.bias',                                           \n",
            "                             'encoder.mid.attn_1.v.weight',                                         \n",
            "                             'encoder.mid.attn_1.v.bias',                                           \n",
            "                             'encoder.mid.attn_1.proj_out.weight',                                  \n",
            "                             'encoder.mid.attn_1.proj_out.bias',                                    \n",
            "                             'encoder.mid.block_2.norm1.weight',                                    \n",
            "                             'encoder.mid.block_2.norm1.bias',                                      \n",
            "                             'encoder.mid.block_2.conv1.weight',                                    \n",
            "                             'encoder.mid.block_2.conv1.bias',                                      \n",
            "                             'encoder.mid.block_2.norm2.weight',                                    \n",
            "                             'encoder.mid.block_2.norm2.bias',                                      \n",
            "                             'encoder.mid.block_2.conv2.weight',                                    \n",
            "                             'encoder.mid.block_2.conv2.bias',                                      \n",
            "                             'encoder.norm_out.weight', 'encoder.norm_out.bias',                    \n",
            "                             'encoder.conv_out.weight', 'encoder.conv_out.bias',                    \n",
            "                             'decoder.conv_in.weight', 'decoder.conv_in.bias',                      \n",
            "                             'decoder.mid.block_1.norm1.weight',                                    \n",
            "                             'decoder.mid.block_1.norm1.bias',                                      \n",
            "                             'decoder.mid.block_1.conv1.weight',                                    \n",
            "                             'decoder.mid.block_1.conv1.bias',                                      \n",
            "                             'decoder.mid.block_1.norm2.weight',                                    \n",
            "                             'decoder.mid.block_1.norm2.bias',                                      \n",
            "                             'decoder.mid.block_1.conv2.weight',                                    \n",
            "                             'decoder.mid.block_1.conv2.bias',                                      \n",
            "                             'decoder.mid.attn_1.norm.weight',                                      \n",
            "                             'decoder.mid.attn_1.norm.bias',                                        \n",
            "                             'decoder.mid.attn_1.q.weight',                                         \n",
            "                             'decoder.mid.attn_1.q.bias',                                           \n",
            "                             'decoder.mid.attn_1.k.weight',                                         \n",
            "                             'decoder.mid.attn_1.k.bias',                                           \n",
            "                             'decoder.mid.attn_1.v.weight',                                         \n",
            "                             'decoder.mid.attn_1.v.bias',                                           \n",
            "                             'decoder.mid.attn_1.proj_out.weight',                                  \n",
            "                             'decoder.mid.attn_1.proj_out.bias',                                    \n",
            "                             'decoder.mid.block_2.norm1.weight',                                    \n",
            "                             'decoder.mid.block_2.norm1.bias',                                      \n",
            "                             'decoder.mid.block_2.conv1.weight',                                    \n",
            "                             'decoder.mid.block_2.conv1.bias',                                      \n",
            "                             'decoder.mid.block_2.norm2.weight',                                    \n",
            "                             'decoder.mid.block_2.norm2.bias',                                      \n",
            "                             'decoder.mid.block_2.conv2.weight',                                    \n",
            "                             'decoder.mid.block_2.conv2.bias',                                      \n",
            "                             'decoder.up.0.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.0.block.0.nin_shortcut.weight',                            \n",
            "                             'decoder.up.0.block.0.nin_shortcut.bias',                              \n",
            "                             'decoder.up.0.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.0.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.0.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.0.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.0.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.0.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.0.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.0.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.0.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.0.nin_shortcut.weight',                            \n",
            "                             'decoder.up.1.block.0.nin_shortcut.bias',                              \n",
            "                             'decoder.up.1.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.1.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.1.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.1.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.1.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.1.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.1.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.1.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.1.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.1.upsample.conv.weight',                                   \n",
            "                             'decoder.up.1.upsample.conv.bias',                                     \n",
            "                             'decoder.up.2.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.2.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.2.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.2.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.2.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.2.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.2.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.2.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.2.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.2.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.2.upsample.conv.weight',                                   \n",
            "                             'decoder.up.2.upsample.conv.bias',                                     \n",
            "                             'decoder.up.3.block.0.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.0.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.0.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.0.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.0.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.0.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.0.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.0.conv2.bias',                                     \n",
            "                             'decoder.up.3.block.1.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.1.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.1.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.1.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.1.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.1.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.1.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.1.conv2.bias',                                     \n",
            "                             'decoder.up.3.block.2.norm1.weight',                                   \n",
            "                             'decoder.up.3.block.2.norm1.bias',                                     \n",
            "                             'decoder.up.3.block.2.conv1.weight',                                   \n",
            "                             'decoder.up.3.block.2.conv1.bias',                                     \n",
            "                             'decoder.up.3.block.2.norm2.weight',                                   \n",
            "                             'decoder.up.3.block.2.norm2.bias',                                     \n",
            "                             'decoder.up.3.block.2.conv2.weight',                                   \n",
            "                             'decoder.up.3.block.2.conv2.bias',                                     \n",
            "                             'decoder.up.3.upsample.conv.weight',                                   \n",
            "                             'decoder.up.3.upsample.conv.bias',                                     \n",
            "                             'decoder.norm_out.weight', 'decoder.norm_out.bias',                    \n",
            "                             'decoder.conv_out.weight', 'decoder.conv_out.bias'],                   \n",
            "                             unexpected_keys=['lora_te_text_model_encoder_layers_0                  \n",
            "                             _mlp_fc1.alpha',                                                       \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_0_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc1.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_mlp_fc2.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_k_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.alpha',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.lora_down.weight',                                                 \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_out_p                  \n",
            "                             roj.lora_up.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_q_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_10_self_attn_v_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc1.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.alpha',                  \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_mlp_fc2.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_k_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.alpha',                                                            \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.lora_down.weight',                                                 \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_out_p                  \n",
            "                             roj.lora_up.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_q_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.alpha',                                                              \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.lora_down.weight',                                                   \n",
            "                             'lora_te_text_model_encoder_layers_11_self_attn_v_pro                  \n",
            "                             j.lora_up.weight',                                                     \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_1_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_2_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_3_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_4_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_5_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_6_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_7_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_8_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc1.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.alpha',                   \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_mlp_fc2.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_k_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.alpha',                                                             \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.lora_down.weight',                                                  \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_out_pr                  \n",
            "                             oj.lora_up.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_q_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .alpha',                                                               \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .lora_down.weight',                                                    \n",
            "                             'lora_te_text_model_encoder_layers_9_self_attn_v_proj                  \n",
            "                             .lora_up.weight',                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_0_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_1_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_0_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.alpha',                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.lora_do                  \n",
            "                             wn.weight',                                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_in.lora_up                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.alpha'                  \n",
            "                             ,                                                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.lora_d                  \n",
            "                             own.weight',                                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_proj_out.lora_u                  \n",
            "                             p.weight',                                                             \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn1_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_k.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.alpha',                                           \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_down.weight',                                \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_out_0.lora_up.weight',                                  \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_q.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.alpha',                                               \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_down.weight',                                    \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_attn2_to_v.lora_up.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.alpha',                                            \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_down.weight',                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_0_proj.lora_up.weight',                                   \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.alpha',                                                 \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_down.weight',                                      \n",
            "                             'lora_unet_down_blocks_2_attentions_1_transformer_blo                  \n",
            "                             cks_0_ff_net_2.lora_up.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.alpha',                      \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.lora_down.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_mid_block_attentions_0_proj_in.lora_up.wei                  \n",
            "                             ght',                                                                  \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.alpha',                     \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.lora_down.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_mid_block_attentions_0_proj_out.lora_up.we                  \n",
            "                             ight',                                                                 \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_k.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.alpha',                                               \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.lora_down.weight',                                    \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_out_0.lora_up.weight',                                      \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_q.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn1_to_v.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_k.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.alpha',                                               \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.lora_down.weight',                                    \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_out_0.lora_up.weight',                                      \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_q.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.alpha',                                                   \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.lora_down.weight',                                        \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_attn2_to_v.lora_up.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.alpha',                                                \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.lora_down.weight',                                     \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_0_proj.lora_up.weight',                                       \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.alpha',                                                     \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.lora_down.weight',                                          \n",
            "                             'lora_unet_mid_block_attentions_0_transformer_blocks_                  \n",
            "                             0_ff_net_2.lora_up.weight',                                            \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_1_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_2_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_0_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_1_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight',                                          \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.alpha',                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_down                  \n",
            "                             .weight',                                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_in.lora_up.w                  \n",
            "                             eight',                                                                \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.alpha',                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_dow                  \n",
            "                             n.weight',                                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_proj_out.lora_up.                  \n",
            "                             weight',                                                               \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn1_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_k.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.alpha',                                             \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_down.weight',                                  \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_out_0.lora_up.weight',                                    \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_q.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.alpha',                                                 \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_down.weight',                                      \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_attn2_to_v.lora_up.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.alpha',                                              \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_down.weight',                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_0_proj.lora_up.weight',                                     \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.alpha',                                                   \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_down.weight',                                        \n",
            "                             'lora_unet_up_blocks_3_attentions_2_transformer_block                  \n",
            "                             s_0_ff_net_2.lora_up.weight'])                                         \n",
            "import network module: .networks.lora_flux\n",
            "                    ERROR    !!! Exception during processing !!! Cannot copy out of execution.py:396\n",
            "                             meta tensor; no data! Please use                                       \n",
            "                             torch.nn.Module.to_empty() instead of                                  \n",
            "                             torch.nn.Module.to() when moving module from meta to a                 \n",
            "                             different device.                                                      \n",
            "                    ERROR    Traceback (most recent call last):                     execution.py:397\n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 327, in execute                                                   \n",
            "                                 output_data, output_ui, has_subgraph =                             \n",
            "                             get_output_data(obj, input_data_all,                                   \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                                        ^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 202, in get_output_data                                           \n",
            "                                 return_values = _map_node_over_list(obj,                           \n",
            "                             input_data_all, obj.FUNCTION, allow_interrupt=True,                    \n",
            "                             execution_block_cb=execution_block_cb,                                 \n",
            "                             pre_execute_cb=pre_execute_cb)                                         \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                 \n",
            "                             ^^^^                                                                   \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 174, in _map_node_over_list                                       \n",
            "                                 process_inputs(input_dict, i)                                      \n",
            "                               File \"/content/drive/MyDrive/ComfyUI/execution.py\",                  \n",
            "                             line 163, in process_inputs                                            \n",
            "                                 results.append(getattr(obj, func)(**inputs))                       \n",
            "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                        \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/nodes.py\", line 631, in init_training                       \n",
            "                                 training_loop = network_trainer.init_train(args)                   \n",
            "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \n",
            "                               File                                                                 \n",
            "                             \"/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-f                 \n",
            "                             luxtrainer/train_network.py\", line 449, in init_train                  \n",
            "                                 vae.to(accelerator.device, dtype=vae_dtype)                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1343, in to                                       \n",
            "                                 return self._apply(convert)                                        \n",
            "                                        ^^^^^^^^^^^^^^^^^^^^                                        \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 903, in _apply                                    \n",
            "                                 module._apply(fn)                                                  \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 930, in _apply                                    \n",
            "                                 param_applied = fn(param)                                          \n",
            "                                                 ^^^^^^^^^                                          \n",
            "                               File                                                                 \n",
            "                             \"/usr/local/lib/python3.11/dist-packages/torch/nn/modu                 \n",
            "                             les/module.py\", line 1336, in convert                                  \n",
            "                                 raise NotImplementedError(                                         \n",
            "                             NotImplementedError: Cannot copy out of meta tensor;                   \n",
            "                             no data! Please use torch.nn.Module.to_empty() instead                 \n",
            "                             of torch.nn.Module.to() when moving module from meta                   \n",
            "                             to a different device.                                                 \n",
            "                                                                                                    \n",
            "                    INFO     Prompt executed in 3.29 seconds                             main.py:189\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/4245046894_model-list.json [DONE]\n"
          ]
        }
      ],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}